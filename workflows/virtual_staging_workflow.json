{
  "2": {
    "inputs": {
      "image": "example.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3": {
    "inputs": {
      "pixels": [
        "213",
        0
      ],
      "vae": [
        "7",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "7": {
    "inputs": {
      "ckpt_name": "SDXL\\juggernautXL_ragnarokBy.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "8": {
    "inputs": {
      "type": "canny/lineart/anime_lineart/mlsd",
      "control_net": [
        "12",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "10": {
    "inputs": {
      "strength": 0.15,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "22",
        0
      ],
      "negative": [
        "23",
        0
      ],
      "control_net": [
        "8",
        0
      ],
      "image": [
        "201",
        0
      ],
      "vae": [
        "7",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "12": {
    "inputs": {
      "control_net_name": "controlnet++_union_sdxl_promax.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "14": {
    "inputs": {
      "type": "depth",
      "control_net": [
        "12",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "17": {
    "inputs": {
      "strength": 0.15,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "216",
        0
      ],
      "negative": [
        "216",
        1
      ],
      "control_net": [
        "14",
        0
      ],
      "image": [
        "133",
        0
      ],
      "vae": [
        "7",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "22": {
    "inputs": {
      "text": "Photorealistic modern luxury bedroom with cozy queen bed, plush bedding, sleek nightstand, minimalist lamp, soft rug, modern dresser, and stylish armchair in neutral grays, whites, wood tones. Furniture fits naturally. Daylight through large window casts soft shadows, highlighting textures. Warm lighting creates elegant, lived-in vibe. Detailed textures, accurate perspective.",
      "clip": [
        "7",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "23": {
    "inputs": {
      "text": "Blurry, low-resolution, grainy, under/overexposed, watermark, text, logo, signature, artifacts, out of focus, distorted, cropped, empty, unfurnished, inconsistent perspective, bad integration, unrealistic shadows/textures, cartoonish, anime, 3D render, digital art, sketch, painting, low-quality, cluttered, asymmetrical, bad lighting, oversaturated, artificial, surreal, visual artifacts",
      "clip": [
        "7",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "25": {
    "inputs": {
      "seed": 77702196725357,
      "steps": 30,
      "cfg": 8,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.85,
      "model": [
        "7",
        0
      ],
      "positive": [
        "17",
        0
      ],
      "negative": [
        "17",
        1
      ],
      "latent_image": [
        "3",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "26": {
    "inputs": {
      "samples": [
        "25",
        0
      ],
      "vae": [
        "7",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "80": {
    "inputs": {
      "images": [
        "201",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "87": {
    "inputs": {
      "images": [
        "133",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "126": {
    "inputs": {
      "filename_prefix": "Virtual_Staging",
      "images": [
        "131",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "131": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "factor": 2,
      "upscale_model": [
        "132",
        0
      ],
      "image": [
        "26",
        0
      ]
    },
    "class_type": "Upscale by Factor with Model (WLSH)",
    "_meta": {
      "title": "Upscale by Factor with Model (WLSH)"
    }
  },
  "132": {
    "inputs": {
      "model_name": "4x-UltraSharpV2.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "133": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 512,
      "image": [
        "213",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "Depth Anything V2 - Relative"
    }
  },
  "201": {
    "inputs": {
      "guassian_sigma": 6,
      "intensity_threshold": 8,
      "resolution": 512,
      "image": [
        "213",
        0
      ]
    },
    "class_type": "LineartStandardPreprocessor",
    "_meta": {
      "title": "Standard Lineart"
    }
  },
  "212": {
    "inputs": {
      "resolution": 512,
      "image": [
        "213",
        0
      ]
    },
    "class_type": "OneFormer-ADE20K-SemSegPreprocessor",
    "_meta": {
      "title": "OneFormer ADE20K Segmentor"
    }
  },
  "213": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "factor": 0.5,
      "upscale_model": [
        "132",
        0
      ],
      "image": [
        "2",
        0
      ]
    },
    "class_type": "Upscale by Factor with Model (WLSH)",
    "_meta": {
      "title": "Upscale by Factor with Model (WLSH)"
    }
  },
  "214": {
    "inputs": {
      "type": "segment",
      "control_net": [
        "12",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "215": {
    "inputs": {
      "images": [
        "212",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "216": {
    "inputs": {
      "strength": 0.15,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "10",
        0
      ],
      "negative": [
        "10",
        1
      ],
      "control_net": [
        "214",
        0
      ],
      "image": [
        "212",
        0
      ],
      "vae": [
        "7",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  }
}